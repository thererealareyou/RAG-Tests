import chromadb
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, T5EncoderModel
from rank_bm25 import BM25Okapi
import re

from src.inference import SarcasmPhilosopherInferencer


def pool(hidden_state, mask, pooling_method="cls"):
    if pooling_method == "mean":
        s = torch.sum(hidden_state * mask.unsqueeze(-1).float(), dim=1)
        d = mask.sum(axis=1, keepdim=True).float()
        return s / d
    elif pooling_method == "cls":
        return hidden_state[:, 0]

# === 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ===
tokenizer_emb = AutoTokenizer.from_pretrained("ai-forever/FRIDA", local_files_only=True)
model_emb = T5EncoderModel.from_pretrained("ai-forever/FRIDA", local_files_only=True)

def get_embedding(text):
    tokenized = tokenizer_emb(text, max_length=512, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        outputs = model_emb(**tokenized)
    embeddings = pool(outputs.last_hidden_state, tokenized["attention_mask"], pooling_method="cls")
    embeddings = F.normalize(embeddings, p=2, dim=1)
    return embeddings.cpu().numpy()

def preprocess_text(text):
    """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è BM25: –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –ø–æ –ø—Ä–æ–±–µ–ª–∞–º."""
    tokens = re.findall(r'\w+', text.lower())
    return tokens

# === 2. –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ ===
client = chromadb.PersistentClient(path="src/data")
collection = client.get_collection("outer_wilds_wiki")

# === 2.1. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –∏—Ö ID –∏–∑ –±–∞–∑—ã –¥–ª—è BM25 ===
all_docs_result = collection.get(include=['documents', 'metadatas'])
corpus = all_docs_result['documents']
doc_metadatas = all_docs_result.get('metadatas', [{}] * len(corpus))
doc_ids_from_get = all_docs_result['ids']
print(f"–ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(corpus)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è BM25 –∏–∑ –±–∞–∑—ã Chroma.")

# === 2.2. –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å BM25 –Ω–∞ –æ—Å–Ω–æ–≤–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ –∫–æ—Ä–ø—É—Å–∞ ===
tokenized_corpus = [preprocess_text(doc) for doc in corpus]
print(f"–°–æ–∑–¥–∞–Ω –∏–Ω–¥–µ–∫—Å BM25 –¥–ª—è {len(tokenized_corpus)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
# –û—Ç–ª–∞–¥–∫–∞: –ø–æ—Å–º–æ—Ç—Ä–∏–º –ø–µ—Ä–≤—ã–µ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
# print("–ü—Ä–∏–º–µ—Ä—ã —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:", tokenized_corpus[:2])

bm25 = BM25Okapi(tokenized_corpus)

# === 3. –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å ===
query = "–ö—Ç–æ —Ç–∞–∫–æ–π —É–¥–∏–ª—å—â–∏–∫?"  #  –ó–∞–ø—Ä–æ—Å
print(f"–ó–∞–ø—Ä–æ—Å: '{query}'")

# === 4. –õ–µ–∫—Å–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ (BM25) ===
tokenized_query = preprocess_text(query)
print(f"–¢–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å: {tokenized_query}")

bm25_scores = bm25.get_scores(tokenized_query)
print(f"–ü–æ–ª—É—á–µ–Ω–æ {len(bm25_scores)} –æ—Ü–µ–Ω–æ–∫ BM25 (–¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤).")

# === 4.1. –ü–æ–ª—É—á–∞–µ–º —Ç–æ–ø-N —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ BM25 ===
N_BM25 = 10
top_n_indices_bm25 = sorted(range(len(bm25_scores)), key=lambda i: bm25_scores[i], reverse=True)[:N_BM25]
top_n_docs_bm25 = [corpus[i] for i in top_n_indices_bm25]
top_n_ids_bm25 = [doc_ids_from_get[i] for i in top_n_indices_bm25]
top_n_scores_bm25 = [bm25_scores[i] for i in top_n_indices_bm25]

print(f"–¢–æ–ø-{N_BM25} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ BM25:")
for i, (idx, score) in enumerate(zip(top_n_indices_bm25, top_n_scores_bm25)):
    print(f"  {i+1}. ID: {top_n_ids_bm25[i]}, Score: {score:.4f}, Doc: '{top_n_docs_bm25[i][:100]}...'") # –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤

# === 5. –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ ===
query_embedding = get_embedding(query)

# === 6. –í—ã–ø–æ–ª–Ω—è–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π (–≤–µ–∫—Ç–æ—Ä–Ω—ã–π) –ø–æ–∏—Å–∫ ===
N_VECTOR = 10
vector_results = collection.query(
    query_embeddings=query_embedding,
    n_results=N_VECTOR
)

# === 6.1. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ ===
vector_docs = vector_results['documents'][0]
vector_doc_ids = vector_results['ids'][0]
vector_distances = vector_results['distances'][0]
vector_scores = [1 - d for d in vector_distances]

print(f"–¢–æ–ø-{N_VECTOR} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º—É –ø–æ–∏—Å–∫—É:")
for i, (doc_id, v_score, dist) in enumerate(zip(vector_doc_ids, vector_scores, vector_distances)):
    print(f"  {i+1}. ID: {doc_id}, Vector Score: {v_score:.4f}, Distance: {dist:.4f}, Doc: '{vector_docs[i][:100]}...'") # –ü–µ—á–∞—Ç–∞–µ–º –ø–µ—Ä–≤—ã–µ 100 —Å–∏–º–≤–æ–ª–æ–≤

# === 7. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
combined_results = {}

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
print("\n--- –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ ---")
for doc_text, doc_id, v_score in zip(vector_docs, vector_doc_ids, vector_scores):
    print(f"  –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –≤–µ–∫—Ç–æ—Ä–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: ID={doc_id}, Vector Score={v_score:.4f}")
    if doc_id in combined_results:
        combined_results[doc_id]['vector_score'] = max(v_score, combined_results[doc_id]['vector_score'])
        print(f"    –û–±–Ω–æ–≤–ª—ë–Ω –≤–µ–∫—Ç–æ—Ä–Ω—ã–π —Å–∫–æ—Ä –¥–ª—è ID {doc_id}")
    else:
        # –ù—É–∂–Ω–æ –Ω–∞–π—Ç–∏ BM25 –æ—Ü–µ–Ω–∫—É –¥–ª—è —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        # –ù–∞–π–¥—ë–º –∏–Ω–¥–µ–∫—Å –¥–æ–∫—É–º–µ–Ω—Ç–∞ –≤ corpus –ø–æ –µ–≥–æ ID
        try:
            doc_idx_in_corpus = doc_ids_from_get.index(doc_id)
            print(f"    –ù–∞–π–¥–µ–Ω –∏–Ω–¥–µ–∫—Å –≤ –∫–æ—Ä–ø—É—Å–µ: {doc_idx_in_corpus}")
            # –ü–æ–ª—É—á–∏–º –æ—Ü–µ–Ω–∫—É BM25 –¥–ª—è —ç—Ç–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
            b_score = bm25_scores[doc_idx_in_corpus]
            print(f"    BM25 Score –¥–ª—è —ç—Ç–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {b_score:.4f}")
        except ValueError:
            print(f"    –û–®–ò–ë–ö–ê: ID {doc_id} –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ —Å–ø–∏—Å–∫–µ ID –∏–∑ collection.get()!")
            b_score = 0.0 # –ï—Å–ª–∏ ID –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º 0

        combined_results[doc_id] = {
            'document': doc_text,
            'vector_score': v_score,
            'bm25_score': b_score,
        }
        print(f"    –î–æ–±–∞–≤–ª–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç –≤ combined_results —Å BM25 Score: {b_score:.4f}")

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã BM25 (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –ø–æ–∏—Å–∫–µ)
print("\n--- –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã BM25 (–µ—Å–ª–∏ ID –Ω–µ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–º –ø–æ–∏—Å–∫–µ) ---")
for doc_text, doc_id, b_score in zip(top_n_docs_bm25, top_n_ids_bm25, top_n_scores_bm25):
    print(f"  –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é BM25 —Ä–µ–∑—É–ª—å—Ç–∞—Ç: ID={doc_id}, BM25 Score={b_score:.4f}")
    if doc_id in combined_results:
        # –û–±–Ω–æ–≤–ª—è–µ–º BM25 score, –µ—Å–ª–∏ –æ–Ω –≤—ã—à–µ
        if b_score > combined_results[doc_id]['bm25_score']:
             combined_results[doc_id]['bm25_score'] = b_score
             print(f"    –û–±–Ω–æ–≤–ª—ë–Ω BM25 —Å–∫–æ—Ä –¥–ª—è ID {doc_id} –¥–æ {b_score:.4f}")
        else:
             print(f"    BM25 —Å–∫–æ—Ä ({b_score:.4f}) –Ω–µ –≤—ã—à–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ ({combined_results[doc_id]['bm25_score']:.4f}) –¥–ª—è ID {doc_id}")
    else:
        print(f"    –î–æ–±–∞–≤–ª–µ–Ω –Ω–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ BM25 –≤ combined_results")
        combined_results[doc_id] = {
            'document': doc_text,
            'vector_score': 0.0,
            'bm25_score': b_score,
        }

# === 8. –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
WEIGHT_VECTOR = 0.4
WEIGHT_BM25 = 0.6

def calculate_hybrid_score(result):
    v_score = result['vector_score']
    b_score = result['bm25_score']
    return WEIGHT_VECTOR * v_score + WEIGHT_BM25 * b_score

sorted_results_with_id = sorted(combined_results.items(), key=lambda item: calculate_hybrid_score(item[1]), reverse=True)

# === 9. –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ø-K —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ ===
K_FINAL = 10
final_results_data = [item[1] for item in sorted_results_with_id[:K_FINAL]]
final_docs = [res['document'] for res in final_results_data]

print("\nüîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫):")
for i, (doc_id, res_data) in enumerate(sorted_results_with_id[:K_FINAL]):
    score = calculate_hybrid_score(res_data)
    print(f"Doc {i+1} (ID: {doc_id}): Score={score:.4f}, Vector={res_data['vector_score']:.4f}, BM25={res_data['bm25_score']:.4f}")
    print(f"Text: {res_data['document']}")
    print("-" * 50)

# === 10. –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM ===
context = "\n".join(final_docs)

prompt = f"""
–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context}

–í–æ–ø—Ä–æ—Å: {query}

–û—Ç–≤–µ—Ç:
"""

SPI = SarcasmPhilosopherInferencer()
answer = SPI.generate_response(user_prompt=prompt)
print(answer['response'])